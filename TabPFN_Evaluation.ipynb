{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installation TabPFN"
      ],
      "metadata": {
        "id": "m1rFnvN1Kg8H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLq4vzAwyGWH",
        "outputId": "68e337a5-04bd-4f07-a34c-cd43a06ad68e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2mUsing Python 3.12.11 environment at: /usr\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m21 packages\u001b[0m \u001b[2min 481ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 4.52s\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 10ms\u001b[0m\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mcatboost\u001b[0m\u001b[2m==1.2.8\u001b[0m\n",
            "\u001b[2mUsing Python 3.12.11 environment at: /usr\u001b[0m\n",
            "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 381ms\u001b[0m\u001b[0m\n",
            "\u001b[2mUsing Python 3.12.11 environment at: /usr\u001b[0m\n",
            "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 273ms\u001b[0m\u001b[0m\n",
            "\u001b[2mUsing Python 3.12.11 environment at: /usr\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m26 packages\u001b[0m \u001b[2min 277ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m4 packages\u001b[0m \u001b[2min 113ms\u001b[0m\u001b[0m\n",
            "\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 2ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m4 packages\u001b[0m \u001b[2min 17ms\u001b[0m\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpassword-strength\u001b[0m\u001b[2m==0.0.3.post2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msseclient-py\u001b[0m\u001b[2m==1.8.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtabpfn-client\u001b[0m\u001b[2m==0.1.10\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mtyping-extensions\u001b[0m\u001b[2m==4.15.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtyping-extensions\u001b[0m\u001b[2m==4.14.1\u001b[0m\n",
            "Cloning into 'tabpfn'...\n",
            "remote: Enumerating objects: 110, done.\u001b[K\n",
            "remote: Counting objects: 100% (110/110), done.\u001b[K\n",
            "remote: Compressing objects: 100% (97/97), done.\u001b[K\n",
            "remote: Total 110 (delta 11), reused 54 (delta 8), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (110/110), 1.46 MiB | 6.02 MiB/s, done.\n",
            "Resolving deltas: 100% (11/11), done.\n",
            "\u001b[2mUsing Python 3.12.11 environment at: /usr\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m32 packages\u001b[0m \u001b[2min 547ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m2 packages\u001b[0m \u001b[2min 2.31s\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m2 packages\u001b[0m \u001b[2min 3ms\u001b[0m\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1meval-type-backport\u001b[0m\u001b[2m==0.2.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtabpfn\u001b[0m\u001b[2m==2.1.3 (from file:///content/tabpfn)\u001b[0m\n",
            "Cloning into 'tabpfn-extensions'...\n",
            "remote: Enumerating objects: 3114, done.\u001b[K\n",
            "remote: Counting objects: 100% (958/958), done.\u001b[K\n",
            "remote: Compressing objects: 100% (318/318), done.\u001b[K\n",
            "remote: Total 3114 (delta 791), reused 654 (delta 631), pack-reused 2156 (from 2)\u001b[K\n",
            "Receiving objects: 100% (3114/3114), 1.21 MiB | 12.07 MiB/s, done.\n",
            "Resolving deltas: 100% (1913/1913), done.\n",
            "\u001b[2mUsing Python 3.12.11 environment at: /usr\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m65 packages\u001b[0m \u001b[2min 792ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m12 packages\u001b[0m \u001b[2min 2.06s\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m12 packages\u001b[0m \u001b[2min 81ms\u001b[0m\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mautogluon-common\u001b[0m\u001b[2m==1.4.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mautogluon-core\u001b[0m\u001b[2m==1.4.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mautogluon-features\u001b[0m\u001b[2m==1.4.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mautogluon-tabular\u001b[0m\u001b[2m==1.4.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mboto3\u001b[0m\u001b[2m==1.40.27\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mbotocore\u001b[0m\u001b[2m==1.40.27\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mgalois\u001b[0m\u001b[2m==0.4.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mjmespath\u001b[0m\u001b[2m==1.0.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1ms3transfer\u001b[0m\u001b[2m==0.14.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mshapiq\u001b[0m\u001b[2m==1.3.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1msparse-transform\u001b[0m\u001b[2m==0.2.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtabpfn-extensions\u001b[0m\u001b[2m==0.1.4 (from file:///content/tabpfn-extensions)\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "## Base library Installation\n",
        "# Install Baselines for model comparison\n",
        "!uv pip install catboost xgboost\n",
        "\n",
        "# Install the datasets library for loading example data\n",
        "!uv pip install datasets\n",
        "\n",
        "# Install rich for better and more readable printing\n",
        "!uv pip install rich\n",
        "\n",
        "\n",
        "## TabPFN Installation optimized for Google Colab\n",
        "# Install the TabPFN Client library\n",
        "!uv pip install tabpfn-client\n",
        "\n",
        "# Install tabpfn from source\n",
        "# Clone the repository: shallow for speedup\n",
        "!git clone --depth 1 https://github.com/PriorLabs/tabpfn\n",
        "\n",
        "# Speeding up installation in this notebook:\n",
        "# Remove torch dependency as it is already installed on colab (do not run this in your local setup)\n",
        "!sed -i \"/torch/d\" tabpfn/pyproject.toml\n",
        "\n",
        "# Step 3: Install using the correct directory name 'tabpfn'\n",
        "!uv pip install -e \"tabpfn\"\n",
        "\n",
        "# Install TabPFN extensions for additional functionalities\n",
        "!git clone https://github.com/PriorLabs/tabpfn-extensions\n",
        "\n",
        "# Speeding up installation in this notebook:\n",
        "# Remove torch dependency as it is already installed on colab (do not run this in your local setup)\n",
        "!sed -i \"/torch/d\" tabpfn-extensions/pyproject.toml\n",
        "\n",
        "!uv pip install -e tabpfn-extensions[all]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mounting datasets:"
      ],
      "metadata": {
        "id": "ysJb8MW5NGno"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/MyDrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VlH_73YNDu0",
        "outputId": "0d1450f0-ba5e-49e5-86d2-8ff1742ac811"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset hill-valley (OpenML ID = 1479)\n",
        "\n",
        "## TabPFN:"
      ],
      "metadata": {
        "id": "8ZroXYfUKgT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from tabpfn_client import TabPFNClassifier, init\n",
        "\n",
        "init()\n",
        "\n",
        "# Pick the best available device\n",
        "device = \"cuda\" if torch.cuda.is_available() else (\n",
        "    \"mps\" if getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available() else \"cpu\"\n",
        ")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Load a CLASSIFICATION dataset (OpenML 1479)  ‚Üê already categorical labels\n",
        "df = fetch_openml(data_id=1479, as_frame=True)\n",
        "X = df.data.to_numpy().astype(np.float32)   # keep inputs float32 for GPU memory efficiency\n",
        "y = df.target.to_numpy()                    # TabPFN handles discrete targets\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.5, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Initialize classifier on GPU (or MPS/CPU fallback)\n",
        "clf = TabPFNClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "proba = clf.predict_proba(X_test)\n",
        "#print(\"ROC AUC:\", roc_auc_score(y_test, proba, multi_class=\"ovr\"))\n",
        "print(\"ROC AUC:\", roc_auc_score(y_test.ravel(), proba[:, 1]))\n",
        "\n",
        "pred = clf.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test.astype(int), pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlmUo5WW2SEu",
        "outputId": "d86875f3-b2a1-486f-db67-6a75b91320e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Welcome to TabPFN!\n",
            "\n",
            "  TabPFN is still under active development, and we are working hard to make it better.\n",
            "  Please bear with us if you encounter any issues.\n",
            "\n",
            "\n",
            "Opening browser for login. Please complete the login/registration process in your browser and return here.\n",
            "\n",
            "\n",
            "Could not open browser automatically. Falling back to command-line login...\n",
            "\n",
            "  Please choose one of the following options:\n",
            "  (1) Create a TabPFN account\n",
            "  (2) Login to your TabPFN account\n",
            "\n",
            "  Please enter your choice: 1\n",
            "\n",
            "  Please refer to our terms and conditions at: https://www.priorlabs.ai/terms By using TabPFN, you agree to the following terms and conditions:\n",
            "  Do you agree to the above terms and conditions? (y/n): y\n",
            "  Please enter your email: viniciusmatamota08@gmail.com\n",
            "\n",
            "  Password requirements (minimum):\n",
            "  . Length(8)\n",
            "  . Uppercase(1)\n",
            "  . Numbers(1)\n",
            "  . Special(1)\n",
            "\n",
            "  Please enter your password: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "  Password requirements not satisfied.\n",
            "\n",
            "  Please enter your password: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "  Please confirm your password: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "  Entered password and confirmation password do not match, please try again.\n",
            "\n",
            "  Please enter your password: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "  Please confirm your password: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "  Do you agree to not upload personal data? (y/n): y\n",
            "\n",
            "  Please provide your name:\n",
            "  First Name: vinicius\n",
            "  Last Name: mota\n",
            "\n",
            "  Please help us tailor our support and services to your needs\n",
            "\n",
            "  Where do you work?: usp\n",
            "\u001b[1;34mWhat is your current role?\u001b[0m\n",
            "\n",
            "  A. Field practitioner\n",
            "  B. Researcher\n",
            "  C. Student\n",
            "  D. Other\n",
            "\n",
            "========================================\n",
            "\u001b[1;33mEnter the letter of your choice: \u001b[0mC\n",
            "  What do you want to use TabPFN for? Minimum 10 characters.: Research Project\n",
            "  Can we reach out to you via email to support you? (y/n):y\n",
            "  Account created successfully! To start using TabPFN please enter the verification code we sent you by mail.\n",
            "\n",
            "  Please enter the correct verification code sent to your email: lchx0YYY\n",
            "  Email verified successfully!\n",
            "\n",
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| [00:03<00:00]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC AUC: 0.9963729046171944\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| [00:02<00:00]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9735973597359736\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Rain in Australia\n",
        "\n",
        "# TabPFN"
      ],
      "metadata": {
        "id": "KU7t6Ej2KpjK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Without pre-processing of categorical features:"
      ],
      "metadata": {
        "id": "raa9uCG2VtMH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "from tabpfn_client import TabPFNClassifier, init\n",
        "\n",
        "init()\n",
        "\n",
        "# ---- paths ----\n",
        "DATA_DIR = '/content/MyDrive/MyDrive/Datasets/Rain_in_Australia'\n",
        "\n",
        "# ---- device ----\n",
        "device = \"cuda\" if torch.cuda.is_available() else (\n",
        "    \"mps\" if getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available() else \"cpu\"\n",
        ")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# ---- utils ----\n",
        "def load(name):\n",
        "    p = os.path.join(DATA_DIR, name)\n",
        "    return np.load(p, allow_pickle=True) if os.path.exists(p) else None\n",
        "\n",
        "def ravel1d(a):\n",
        "    return a.ravel() if a is not None and a.ndim > 1 else a\n",
        "\n",
        "# ---- load arrays ----\n",
        "C_train, N_train, y_train = load('C_train.npy'), load('N_train.npy'), load('y_train.npy')\n",
        "C_val,   N_val,   y_val   = load('C_val.npy'),   load('N_val.npy'),   load('y_val.npy')\n",
        "C_test,  N_test,  y_test  = load('C_test.npy'),  load('N_test.npy'),  load('y_test.npy')\n",
        "\n",
        "print(\"C_train:\", C_train.shape, C_train.dtype)\n",
        "# ---- build X by concatenating [C | N] ----\n",
        "def concat_features(C_part, N_part):\n",
        "    parts = [p for p in (C_part, N_part) if p is not None]\n",
        "    if not parts:\n",
        "        raise ValueError(\"No features found (need at least C_* or N_*).\")\n",
        "    return np.concatenate(parts, axis=1) if len(parts) > 1 else parts[0]\n",
        "\n",
        "X_train = concat_features(C_train, N_train)\n",
        "X_val   = concat_features(C_val,   N_val) if (C_val is not None or N_val is not None) else None\n",
        "X_test  = concat_features(C_test,  N_test)\n",
        "\n",
        "# Reducing size\n",
        "# Fix seed for reproducibility\n",
        "rng = np.random.default_rng(seed=42)\n",
        "\n",
        "# Random indices for 10k samples\n",
        "idx = rng.choice(X_train.shape[0], size=10000, replace=False)\n",
        "idx2 = rng.choice(X_test.shape[0], size=10000, replace=False)\n",
        "\n",
        "# Subsample\n",
        "X_train = X_train[idx]\n",
        "y_train = y_train[idx]\n",
        "X_test = X_test[idx2]\n",
        "y_test = y_test[idx2]\n",
        "\n",
        "\n",
        "print(\"X_train:\", X_train.shape, X_train.dtype)\n",
        "print(\"X_test :\", X_test.shape,  X_test.dtype)\n",
        "print(\"y_train:\", y_train.shape,  y_train.dtype)\n",
        "print(\"y_test:\", y_test.shape,  y_test.dtype)\n",
        "print(\"y_test  unique:\", np.unique(y_test))\n",
        "\n",
        "# ---- train TabPFN ----\n",
        "clf = TabPFNClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# ---- predict & metrics (multiclass: 3 classes) ----\n",
        "proba = clf.predict_proba(X_test)\n",
        "print(\"ROC AUC (OvR):\", roc_auc_score(y_test, proba, multi_class=\"ovr\"))\n",
        "pred = clf.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whO892AqMNpN",
        "outputId": "d2a41244-ffc6-48a2-a04c-964e7fab7d15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "C_train: (93094, 6) object\n",
            "X_train: (10000, 18) object\n",
            "X_test : (10000, 18) object\n",
            "y_train: (10000,) int64\n",
            "y_test: (10000,) int64\n",
            "y_test  unique: [0 1 2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| [00:29<00:00]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC AUC (OvR): 0.8812873050146299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| [00:29<00:00]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Eye movements"
      ],
      "metadata": {
        "id": "D0GNLZy6LKfb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from tabpfn_client import TabPFNClassifier, init\n",
        "\n",
        "init()\n",
        "\n",
        "# Pick the best available device\n",
        "device = \"cuda\" if torch.cuda.is_available() else (\n",
        "    \"mps\" if getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available() else \"cpu\"\n",
        ")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Load a CLASSIFICATION dataset (OpenML 43946)  ‚Üê already categorical labels\n",
        "df = fetch_openml(data_id=43946, as_frame=True)\n",
        "X = df.data.to_numpy().astype(np.float32)   # keep inputs float32 for GPU memory efficiency\n",
        "y = df.target.to_numpy()                    # TabPFN handles discrete targets\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.5, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(\"X_train:\", X_train.shape, X_train.dtype)\n",
        "print(\"X_test :\", X_test.shape,  X_test.dtype)\n",
        "print(\"y_train:\", y_train.shape,  y_train.dtype)\n",
        "print(\"y_test:\", y_test.shape,  y_test.dtype)\n",
        "print(\"y_test  unique:\", np.unique(y_test))\n",
        "\n",
        "# Initialize classifier on GPU (or MPS/CPU fallback)\n",
        "clf = TabPFNClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "proba = clf.predict_proba(X_test)\n",
        "#print(\"ROC AUC:\", roc_auc_score(y_test, proba, multi_class=\"ovr\"))\n",
        "print(\"ROC AUC:\", roc_auc_score(y_test.ravel(), proba[:, 1]))\n",
        "\n",
        "pred = clf.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78a03824-7769-419e-b72b-69469f04eb76",
        "id": "vTapgyqsLHnR"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "X_train: (3804, 23) float32\n",
            "X_test : (3804, 23) float32\n",
            "y_train: (3804,) int64\n",
            "y_test: (3804,) int64\n",
            "y_test  unique: [0 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| [00:06<00:00]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC AUC: 0.667914868515183\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| [00:05<00:00]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6230283911671924\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Bank note authentication"
      ],
      "metadata": {
        "id": "aiBgTpuSLwl6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def LAC_conformal_score(proba, true_labels):\n",
        "    n_samples = len(true_labels)\n",
        "    true_proba = proba[np.arange(n_samples), true_labels]\n",
        "    conformal_scores = np.ones(n_samples) - true_proba\n",
        "    return conformal_scores\n",
        "\n",
        "def aps_conformal_score(proba, true_labels):\n",
        "    # Create a mask for each sample: scores >= true_score\n",
        "    true_proba = proba[np.arange(proba.shape[0]), true_labels]\n",
        "    mask = proba >= true_proba[:, np.newaxis]\n",
        "    # Sum along the class axis\n",
        "    conformal_scores = np.sum(proba * mask, axis=1)\n",
        "    return conformal_scores\n",
        "\n",
        "def conformal_quantile(scores, alpha):\n",
        "    n = len(scores)\n",
        "    quantile_level = (n + 1) * (1 - alpha) / n\n",
        "    return np.quantile(scores, quantile_level, interpolation=\"higher\")\n",
        "\n",
        "def prediction_set(model, X_test, q_hat):\n",
        "    # Get probabilities from the model\n",
        "    proba = model.predict_proba(X_test)\n",
        "    n_samples, n_classes = proba.shape\n",
        "\n",
        "    # Store conformal scores for each candidate label\n",
        "    s_score_test = np.empty((n_samples, n_classes), dtype=float)\n",
        "\n",
        "    for i in range(n_classes):\n",
        "        y = np.full(n_samples, i, dtype=int)\n",
        "        s_score_test[:, i] = aps_conformal_score(proba, y)\n",
        "\n",
        "    # Build prediction set: keep classes where score ‚â§ q_hat\n",
        "    mask = s_score_test <= q_hat\n",
        "    return mask\n",
        "\n",
        "def set_size(mask):\n",
        "    n_samples, n_classes = mask.shape\n",
        "    avg_set_size = mask.sum()/n_samples\n",
        "\n",
        "    return avg_set_size\n",
        "\n",
        "def coverage_rate(mask, true_labels):\n",
        "    n_samples = len(true_labels)\n",
        "    indicator = mask[np.arange(n_samples), true_labels]\n",
        "\n",
        "    return np.mean(indicator)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cBFO2XtNtPDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "from tabpfn_client import TabPFNClassifier, init\n",
        "\n",
        "init()\n",
        "\n",
        "# ---- paths ----\n",
        "DATA_DIR = '/content/MyDrive/MyDrive/Datasets/banknote_authentication'\n",
        "\n",
        "# ---- device ----\n",
        "device = \"cuda\" if torch.cuda.is_available() else (\n",
        "    \"mps\" if getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available() else \"cpu\"\n",
        ")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# ---- utils ----\n",
        "def load(name):\n",
        "    p = os.path.join(DATA_DIR, name)\n",
        "    return np.load(p, allow_pickle=True) if os.path.exists(p) else None\n",
        "\n",
        "def ravel1d(a):\n",
        "    return a.ravel() if a is not None and a.ndim > 1 else a\n",
        "\n",
        "# ---- load arrays ----\n",
        "N_train, y_train = load('N_train.npy'), load('y_train.npy')\n",
        "N_val,   y_val   = load('N_val.npy'),   load('y_val.npy')\n",
        "N_test,  y_test  = load('N_test.npy'),  load('y_test.npy')\n",
        "\n",
        "# ---- build X by concatenating [C | N] ----\n",
        "def concat_features(C_part, N_part):\n",
        "    parts = [p for p in (C_part, N_part) if p is not None]\n",
        "    if not parts:\n",
        "        raise ValueError(\"No features found (need at least C_* or N_*).\")\n",
        "    return np.concatenate(parts, axis=1) if len(parts) > 1 else parts[0]\n",
        "\n",
        "X_train = N_train\n",
        "X_val   = N_val\n",
        "X_test  = N_test\n",
        "\n",
        "\n",
        "print(\"X_train:\", X_train.shape, X_train.dtype)\n",
        "print(\"X_test :\", X_test.shape,  X_test.dtype)\n",
        "print(\"y_train:\", y_train.shape,  y_train.dtype)\n",
        "print(\"y_test:\", y_test.shape,  y_test.dtype)\n",
        "print(\"y_test  unique:\", np.unique(y_test))\n",
        "\n",
        "# ---- train TabPFN ----\n",
        "clf = TabPFNClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# ---- predict & metrics (multiclass: 3 classes) ----\n",
        "proba = clf.predict_proba(X_test)\n",
        "print(\"ROC AUC (OvR):\", roc_auc_score(y_test.ravel(), proba[:, 1]))\n",
        "pred = clf.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, pred))\n",
        "\n",
        "# ----- Uncertainty Quantification -------\n",
        "proba_cal = clf.predict_proba(X_val) # computes probabilities\n",
        "calibration_scores = aps_conformal_score(proba_cal, y_val) # computes s-score for calibration set\n",
        "q_hat = conformal_quantile(calibration_scores, alpha=0.1) # computes the quantile\n",
        "\n",
        "print(\"Quantile value: \", q_hat)\n",
        "\n",
        "C_test = prediction_set(clf, X_test, q_hat) # computing prediction set\n",
        "cover_rate = coverage_rate(C_test, y_test) # computing the coverage rate of the set C\n",
        "\n",
        "print(\"Coverage rate: \", cover_rate)\n",
        "\n",
        "u_q = set_size(C_test) # computing set size\n",
        "\n",
        "print(\"Set Size: \", u_q)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aq5DvDSOL9wJ",
        "outputId": "182d7821-a5f0-4b71-d699-679bf1e87014"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "X_train: (877, 4) float64\n",
            "X_test : (275, 4) float64\n",
            "y_train: (877,) int64\n",
            "y_test: (275,) int64\n",
            "y_test  unique: [0 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| [00:01<00:00]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC AUC (OvR): 0.4795885567341691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| [00:00<00:00]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5563636363636364\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| [00:00<00:00]\n",
            "/tmp/ipython-input-2209166961.py:64: DeprecationWarning: the `interpolation=` argument to quantile was renamed to `method=`, which has additional options.\n",
            "Users of the modes 'nearest', 'lower', 'higher', or 'midpoint' are encouraged to review the method they used. (Deprecated NumPy 1.22)\n",
            "  q_hat = conformal_quantile(calibration_scores, alpha=0.1) # computes the quantile\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantile:  1.0000000298023224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| [00:01<00:00]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coverage rate:  0.96\n",
            "Set Size:  1.9163636363636363\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numpy._typing import NDArray\n",
        "\n",
        "def confidence_score(probs: NDArray):\n",
        "    return np.max(-probs, axis=1)\n",
        "\n",
        "def margin_score(probs: NDArray):\n",
        "    sorted_probs = np.sort(probs, axis=1)\n",
        "    return sorted_probs[:, -2] - sorted_probs[:, -1]\n",
        "\n",
        "def entropy_score(probs: NDArray, eps = 1e-9):\n",
        "    return -np.sum(probs * np.log(probs + eps), axis=1)\n",
        "\n",
        "def nnl_score(probs: NDArray, true_labels: NDArray, eps = 1e-9):\n",
        "    return -np.log(probs[np.arange(probs.shape[0]), true_labels] + eps)\n",
        "\n",
        "def ri_score(probs: NDArray, eps = 1e-9):\n",
        "    return -np.sum(np.log(probs + eps), axis=1)\n",
        "\n",
        "\n",
        "def lac_conformal_score(probs: NDArray, true_labels: NDArray):\n",
        "    \"\"\"\n",
        "    Compute the LAC conformal score for a batch of softmax score vectors and true labels.\n",
        "\n",
        "    Parameters:\n",
        "    - probs: 2D numpy array of shape (n_samples, num_classes), softmax probs for each sample\n",
        "    - true_labels: 1D numpy array of shape (n_samples,), true class labels for each sample\n",
        "\n",
        "    Returns:\n",
        "    - conformal_scores: 1D numpy array of shape (n_samples,), LAC conformal probs for each sample\n",
        "    \"\"\"\n",
        "    conformal_scores = 1 - probs[np.arange(probs.shape[0]), true_labels]\n",
        "    return conformal_scores\n",
        "\n",
        "def aps_conformal_score(probs: NDArray, true_labels: NDArray):\n",
        "    \"\"\"\n",
        "    Compute the APS conformal score for a batch of softmax score vectors and true labels.\n",
        "\n",
        "    Parameters:\n",
        "    - probs: 2D numpy array of shape (n_samples, num_classes), softmax probs for each sample\n",
        "    - true_labels: 1D numpy array of shape (n_samples,), true class labels for each sample\n",
        "\n",
        "    Returns:\n",
        "    - conformal_scores: 1D numpy array of shape (n_samples,), APS conformal probs for each sample\n",
        "    \"\"\"\n",
        "    # Create a mask for each sample: probs >= true_score\n",
        "    true_scores = probs[np.arange(probs.shape[0]), true_labels]\n",
        "    mask = probs >= true_scores[:, np.newaxis]\n",
        "    # Sum along the class axis\n",
        "    conformal_scores = np.sum(probs * mask, axis=1)\n",
        "\n",
        "    return conformal_scores\n",
        "\n",
        "def compute_quantile(probs: NDArray, calibration_labels, n: int, type = \"lac\", alpha = 0.1):\n",
        "    if type == \"lac\":\n",
        "        scores = lac_conformal_score(probs, calibration_labels)\n",
        "    elif type == \"aps\":\n",
        "        scores = aps_conformal_score(probs, calibration_labels)\n",
        "    else:\n",
        "        raise AttributeError(f\"type {type} is not supported. Use 'lac' or 'aps'\")\n",
        "\n",
        "    q_level = np.ceil((n + 1) * (1 - alpha)) / n\n",
        "    return np.quantile(scores, q_level, method=\"higher\")\n",
        "\n",
        "def lac_prediction_set(calibration_probs: NDArray, probs: NDArray, calibration_labels: NDArray, alpha = 0.1):\n",
        "    n = calibration_labels.shape[0]\n",
        "    cal_scores = 1 - calibration_probs[np.arange(calibration_probs.shape[0]), calibration_labels]\n",
        "    # Get the score quantile\n",
        "\n",
        "    q_level = np.ceil((n + 1) * (1 - alpha)) / n\n",
        "    qhat = np.quantile(cal_scores, q_level, method='higher')\n",
        "\n",
        "    prediction_sets = probs >= (1 - qhat)\n",
        "    return prediction_sets\n",
        "\n",
        "def aps_prediction_set(calibration_probs: NDArray, probs: NDArray, calibration_labels: NDArray, alpha = 0.1):\n",
        "    # Get scores. calib_X.shape[0] == calib_Y.shape[0] == n\n",
        "    n = calibration_labels.shape[0]\n",
        "    cal_order = calibration_probs.argsort(1)[:,::-1]\n",
        "    # cal_sum = cal_probs[np.arange(n)[:, None], cal_pi].cumsum(axis=1)\n",
        "    cal_sum = np.take_along_axis(calibration_probs, cal_order, axis=1).cumsum(axis=1)\n",
        "    cal_scores = np.take_along_axis(cal_sum, cal_order.argsort(axis=1), axis=1)[range(n),calibration_labels]\n",
        "\n",
        "    # Get the score quantile\n",
        "    q_level = np.ceil((n + 1) * (1 - alpha)) / n\n",
        "    qhat = np.quantile(cal_scores, q_level, method='higher')\n",
        "\n",
        "    # Deploy (output=list of length n, each element is tensor of classes)\n",
        "    test_order = probs.argsort(1)[:,::-1]\n",
        "    test_sum = np.take_along_axis(probs,test_order,axis=1).cumsum(axis=1)\n",
        "    prediction_sets = np.take_along_axis(test_sum <= qhat, test_order.argsort(axis=1), axis=1)\n",
        "    return prediction_sets\n",
        "\n",
        "def raps_prediction_set(calibration_probs: NDArray, test_probs: NDArray, calibration_labels: NDArray, alpha = 0.1, lam_reg=0.01, k_reg = 5, disallow_zero_sets = False, rand = True):\n",
        "    probs = np.concatenate([calibration_probs, test_probs], axis=0)\n",
        "    k_reg = min(k_reg, probs.shape[1] - 1)\n",
        "    reg_vec = np.array(k_reg * [0,] + (probs.shape[1] - k_reg) * [lam_reg,])[None, :]\n",
        "\n",
        "    n = calibration_labels.shape[0]\n",
        "    cal_order = calibration_probs.argsort(axis=1)[:,::-1]\n",
        "    cal_sort = np.take_along_axis(calibration_probs, cal_order, axis=1)\n",
        "    cal_sort_reg = cal_sort + reg_vec\n",
        "    cal_true_labels = np.where(cal_order == calibration_labels[:,None])[1]\n",
        "    cal_scores = cal_sort_reg.cumsum(axis=1)[np.arange(n), cal_true_labels] - np.random.rand(n) * cal_sort_reg[np.arange(n), cal_true_labels]\n",
        "\n",
        "    # Get the score quantile\n",
        "    q_level = np.ceil((n + 1) * (1 - alpha)) / n\n",
        "    qhat = np.quantile(cal_scores, q_level, method='higher')\n",
        "\n",
        "    n_test = test_probs.shape[0]\n",
        "    test_order = test_probs.argsort(1)[:,::-1]\n",
        "    test_sort = np.take_along_axis(test_probs, test_order, axis=1)\n",
        "    test_sort_reg = test_sort + reg_vec\n",
        "    test_srt_reg_cumsum = test_sort_reg.cumsum(axis=1)\n",
        "    indicators = (test_srt_reg_cumsum - np.random.rand(n_test, 1) * test_sort_reg) <= qhat if rand else test_srt_reg_cumsum - test_sort_reg <= qhat\n",
        "\n",
        "    if disallow_zero_sets: indicators[:,0] = True\n",
        "    prediction_sets = np.take_along_axis(indicators, test_order.argsort(axis=1), axis=1)\n",
        "    return prediction_sets\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "    return np.mean(y_true == y_pred)\n",
        "\n",
        "def set_size(pred_set):\n",
        "    return np.mean([np.sum(ps) for ps in pred_set])\n",
        "\n",
        "def coverage_rate(y_true, pred_set):\n",
        "    return pred_set[np.arange(pred_set.shape[0]), y_true].mean()"
      ],
      "metadata": {
        "id": "mZLsh-BYUHZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "from tabpfn_client import TabPFNClassifier, init\n",
        "\n",
        "init()\n",
        "\n",
        "# ---- paths ----\n",
        "DATA_DIR = '/content/MyDrive/MyDrive/Datasets/banknote_authentication'\n",
        "\n",
        "# ---- device ----\n",
        "device = \"cuda\" if torch.cuda.is_available() else (\n",
        "    \"mps\" if getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available() else \"cpu\"\n",
        ")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# ---- utils ----\n",
        "def load(name):\n",
        "    p = os.path.join(DATA_DIR, name)\n",
        "    return np.load(p, allow_pickle=True) if os.path.exists(p) else None\n",
        "\n",
        "def ravel1d(a):\n",
        "    return a.ravel() if a is not None and a.ndim > 1 else a\n",
        "\n",
        "# ---- load arrays ----\n",
        "N_train, y_train = load('N_train.npy'), load('y_train.npy')\n",
        "N_val,   y_val   = load('N_val.npy'),   load('y_val.npy')\n",
        "N_test,  y_test  = load('N_test.npy'),  load('y_test.npy')\n",
        "\n",
        "# ---- build X by concatenating [C | N] ----\n",
        "def concat_features(C_part, N_part):\n",
        "    parts = [p for p in (C_part, N_part) if p is not None]\n",
        "    if not parts:\n",
        "        raise ValueError(\"No features found (need at least C_* or N_*).\")\n",
        "    return np.concatenate(parts, axis=1) if len(parts) > 1 else parts[0]\n",
        "\n",
        "X_train = N_train\n",
        "X_val   = N_val\n",
        "X_test  = N_test\n",
        "\n",
        "\n",
        "print(\"X_train:\", X_train.shape, X_train.dtype)\n",
        "print(\"X_test :\", X_test.shape,  X_test.dtype)\n",
        "print(\"y_train:\", y_train.shape,  y_train.dtype)\n",
        "print(\"y_test:\", y_test.shape,  y_test.dtype)\n",
        "print(\"y_test  unique:\", np.unique(y_test))\n",
        "\n",
        "# ---- train TabPFN ----\n",
        "clf = TabPFNClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# ---- predict & metrics (multiclass: 3 classes) ----\n",
        "proba = clf.predict_proba(X_test)\n",
        "proba_cal = clf.predict_proba(X_val) # computes probabilities"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FNANlUCCT8l9",
        "outputId": "a2c0b2b7-5899-4eee-ff94-49c03ac3c596"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Welcome to TabPFN!\n",
            "\n",
            "  TabPFN is still under active development, and we are working hard to make it better.\n",
            "  Please bear with us if you encounter any issues.\n",
            "\n",
            "\n",
            "Opening browser for login. Please complete the login/registration process in your browser and return here.\n",
            "\n",
            "\n",
            "Could not open browser automatically. Falling back to command-line login...\n",
            "\n",
            "  Please choose one of the following options:\n",
            "  (1) Create a TabPFN account\n",
            "  (2) Login to your TabPFN account\n",
            "\n",
            "  Please enter your choice: 1\n",
            "\n",
            "  Please refer to our terms and conditions at: https://www.priorlabs.ai/terms By using TabPFN, you agree to the following terms and conditions:\n",
            "  Do you agree to the above terms and conditions? (y/n): y\n",
            "  Please enter your email: deodato.neto@ga.ita.br\n",
            "\n",
            "  Password requirements (minimum):\n",
            "  . Length(8)\n",
            "  . Uppercase(1)\n",
            "  . Numbers(1)\n",
            "  . Special(1)\n",
            "\n",
            "  Please enter your password: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "  Please confirm your password: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "  Entered password and confirmation password do not match, please try again.\n",
            "\n",
            "  Please enter your password: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "  Please confirm your password: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "  Do you agree to not upload personal data? (y/n): y\n",
            "\n",
            "  Please provide your name:\n",
            "  First Name: Deodato\n",
            "  Last Name: Vasconcelos\n",
            "\n",
            "  Please help us tailor our support and services to your needs\n",
            "\n",
            "  Where do you work?: CentraleSup√©lec\n",
            "\u001b[1;34mWhat is your current role?\u001b[0m\n",
            "\n",
            "  A. Field practitioner\n",
            "  B. Researcher\n",
            "  C. Student\n",
            "  D. Other\n",
            "\n",
            "========================================\n",
            "\u001b[1;33mEnter the letter of your choice: \u001b[0mC\n",
            "  What do you want to use TabPFN for? Minimum 10 characters.: School project\n",
            "  Can we reach out to you via email to support you? (y/n):y\n",
            "  Account created successfully! To start using TabPFN please enter the verification code we sent you by mail.\n",
            "\n",
            "  Please enter the correct verification code sent to your email: ADDm14kc\n",
            "  Email verified successfully!\n",
            "\n",
            "Using device: cpu\n",
            "X_train: (877, 4) float64\n",
            "X_test : (275, 4) float64\n",
            "y_train: (877,) int64\n",
            "y_test: (275,) int64\n",
            "y_test  unique: [0 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| [00:01<00:00]\n",
            "Processing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| [00:01<00:00]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'cal_proba' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2215244686.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0mproba_cal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# computes probabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mlac_pred_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlac_prediction_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcal_proba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0maps_pred_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maps_prediction_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcal_proba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0mraps_pred_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraps_prediction_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcal_proba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cal_proba' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lac_pred_set = lac_prediction_set(proba_cal, proba, y_val)\n",
        "aps_pred_set = aps_prediction_set(proba_cal, proba, y_val)\n",
        "raps_pred_set = raps_prediction_set(proba_cal, proba, y_val)\n",
        "\n",
        "print(\"ROC AUC:\", roc_auc_score(y_test, proba[:,1]))\n",
        "y_pred = np.argmax(proba, axis=1)\n",
        "if hasattr(clf, \"label_encoder_\") and clf.label_encoder_ is not None:\n",
        "    y_pred = clf.label_encoder_.inverse_transform(y_pred)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"SS (LAC):\", set_size(lac_pred_set))\n",
        "print(\"SS (APS):\", set_size(aps_pred_set))\n",
        "print(\"SS (RAPS):\", set_size(raps_pred_set))\n",
        "print(\"CR (LAC):\", coverage_rate(y_test, lac_pred_set))\n",
        "print(\"CR (APS):\", coverage_rate(y_test, aps_pred_set))\n",
        "print(\"CR (RAPS):\", coverage_rate(y_test, raps_pred_set))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwcs7f1jVFYf",
        "outputId": "342ee3b6-51c1-427c-cece-1ebf080d3acd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC AUC: 0.4915354119789993\n",
            "Accuracy: 0.5563636363636364\n",
            "SS (LAC): 1.6181818181818182\n",
            "SS (APS): 1.9272727272727272\n",
            "SS (RAPS): 1.8109090909090908\n",
            "CR (LAC): 0.8290909090909091\n",
            "CR (APS): 0.9709090909090909\n",
            "CR (RAPS): 0.9163636363636364\n"
          ]
        }
      ]
    }
  ]
}